{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe4e220e-829f-46c8-88f2-1814b82f1a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from datetime import datetime\n",
    "\n",
    "# Load datasets\n",
    "customers_df = pd.read_csv(\"C:/Users/Ishan Das/OneDrive/Desktop/ZOPTAP ASSISMENT/Customers.csv\")\n",
    "products_df = pd.read_csv(\"C:/Users/Ishan Das/OneDrive/Desktop/ZOPTAP ASSISMENT/Products.csv\")\n",
    "transactions_df = pd.read_csv(\"C:/Users/Ishan Das/OneDrive/Desktop/ZOPTAP ASSISMENT/Transactions.csv\")\n",
    "# Convert 'SignupDate' and 'TransactionDate' to datetime\n",
    "customers_df['SignupDate'] = pd.to_datetime(customers_df['SignupDate'])\n",
    "transactions_df['TransactionDate'] = pd.to_datetime(transactions_df['TransactionDate'])\n",
    "\n",
    "# Merge customer and transaction data\n",
    "merged_df = pd.merge(transactions_df, customers_df, on='CustomerID')\n",
    "\n",
    "# Merge with product data to get product details\n",
    "merged_df = pd.merge(merged_df, products_df, on='ProductID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f6fca6b8-18f3-4966-8e60-322921c5a129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TransactionID', 'CustomerID', 'ProductID', 'TransactionDate',\n",
      "       'Quantity', 'TotalValue', 'Price_x', 'CustomerName', 'Region',\n",
      "       'SignupDate', 'ProductName', 'Category', 'Price_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# After merging the transactions with product data, check the column names\n",
    "print(merged_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4a223128-5f11-4689-89da-de52efca2f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TransactionID', 'CustomerID', 'ProductID', 'TransactionDate',\n",
      "       'Quantity', 'TotalValue', 'Price_x', 'CustomerName', 'Region',\n",
      "       'SignupDate', 'ProductName', 'Category', 'Price_y', 'Price'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Merge the transactions with product data (including 'Price' column)\n",
    "merged_df = pd.merge(merged_df, products_df[['ProductID', 'Price']], on='ProductID', how='left')\n",
    "\n",
    "# Check the column names again to ensure 'Price' is present\n",
    "print(merged_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b812434e-2f11-4db6-9456-79c8842c29bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "# Check the data type of the 'Price' column\n",
    "print(merged_df['Price'].dtype)\n",
    "\n",
    "# If necessary, convert 'Price' to numeric\n",
    "merged_df['Price'] = pd.to_numeric(merged_df['Price'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f8093bf7-20a6-4df5-a4ef-a0e5471ab775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID  Monetary\n",
      "0      C0001   1391.67\n",
      "1      C0002    835.68\n",
      "2      C0003    782.83\n",
      "3      C0004   1925.09\n",
      "4      C0005    874.81\n"
     ]
    }
   ],
   "source": [
    "# Monetary: Total spending per customer (sum of prices of products purchased)\n",
    "monetary_df = merged_df.groupby('CustomerID')['Price'].sum().reset_index(name='Monetary')\n",
    "\n",
    "# Check the result\n",
    "print(monetary_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "54092fe8-2bc8-4f55-8297-ee0ec0ea7da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID     TransactionDate  Recency  Frequency  Monetary  Books  \\\n",
      "0      C0001 2024-11-02 17:04:16       86          5   1391.67      1   \n",
      "1      C0002 2024-12-03 01:41:41       55          4    835.68      0   \n",
      "2      C0003 2024-08-24 18:54:04      156          4    782.83      0   \n",
      "3      C0004 2024-12-23 14:13:52       35          8   1925.09      3   \n",
      "4      C0005 2024-11-04 00:30:22       84          3    874.81      0   \n",
      "\n",
      "   Clothing  Electronics  Home Decor         Region  SignupYear  SignupMonth  \n",
      "0         0            3           1  South America        2022            7  \n",
      "1         2            0           2           Asia        2022            2  \n",
      "2         1            1           2  South America        2024            3  \n",
      "3         0            2           3  South America        2022           10  \n",
      "4         0            2           1           Asia        2022            8  \n"
     ]
    }
   ],
   "source": [
    "# Recency: How many days ago the customer made the last purchase\n",
    "recency_df = merged_df.groupby('CustomerID')['TransactionDate'].max().reset_index()\n",
    "recency_df['Recency'] = (datetime.now() - recency_df['TransactionDate']).dt.days\n",
    "\n",
    "# Frequency: Total number of transactions per customer\n",
    "frequency_df = merged_df.groupby('CustomerID').size().reset_index(name='Frequency')\n",
    "\n",
    "# Monetary: Total spending per customer (sum of prices of products purchased)\n",
    "monetary_df = merged_df.groupby('CustomerID')['Price'].sum().reset_index(name='Monetary')\n",
    "\n",
    "# Product preferences: This could be the number of purchases per product category\n",
    "category_df = merged_df.groupby(['CustomerID', 'Category']).size().unstack(fill_value=0)\n",
    "\n",
    "# Merge all the features together\n",
    "customer_features = recency_df.merge(frequency_df, on='CustomerID').merge(monetary_df, on='CustomerID')\n",
    "customer_features = customer_features.merge(category_df, on='CustomerID')\n",
    "\n",
    "# Merge with profile features (Region and SignupYear/Month)\n",
    "customer_features = customer_features.merge(customers_df[['CustomerID', 'Region', 'SignupDate']], on='CustomerID')\n",
    "customer_features['SignupYear'] = customer_features['SignupDate'].dt.year\n",
    "customer_features['SignupMonth'] = customer_features['SignupDate'].dt.month\n",
    "\n",
    "# Drop SignupDate column as it's no longer needed\n",
    "customer_features = customer_features.drop(columns=['SignupDate'])\n",
    "\n",
    "# Display the engineered features\n",
    "print(customer_features.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "da74da5c-f6a0-4860-aeda-65fb36cd3710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.26088317 -0.01145819  0.03332559 -0.3211125  -1.04160638  1.55087763\n",
      "  -0.22104388]\n",
      " [-0.69916973 -0.46749414 -0.80691867 -1.22113205  0.77663634 -1.14846331\n",
      "   0.67666495]\n",
      " [ 0.72879617 -0.46749414 -0.88678865 -1.22113205 -0.13248502 -0.248683\n",
      "   0.67666495]\n",
      " [-0.98193525  1.35664965  0.83946076  1.47892659 -1.04160638  0.65109731\n",
      "   1.57437379]\n",
      " [-0.28915972 -0.92353008 -0.74778315 -1.22113205 -1.04160638  0.65109731\n",
      "  -0.22104388]]\n"
     ]
    }
   ],
   "source": [
    "# Select only the numeric columns for scaling (exclude CustomerID, Region, and any datetime columns)\n",
    "numeric_features = customer_features.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(numeric_features)\n",
    "\n",
    "# Display the scaled features (first 5 rows)\n",
    "print(scaled_features[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4614443b-629b-4115-b5a2-b0e14c772df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between customers based on the scaled features\n",
    "cosine_sim = cosine_similarity(scaled_features)\n",
    "\n",
    "# Convert the cosine similarity matrix to a DataFrame for easy manipulation\n",
    "cosine_sim_df = pd.DataFrame(cosine_sim, index=customer_features['CustomerID'], columns=customer_features['CustomerID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f89366a7-2d03-4f17-b9a4-1d8d2a7a4e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Lookalike1    Score1 Lookalike2    Score2 Lookalike3    Score3\n",
      "C0001      C0069  0.944409      C0146  0.784552      C0127  0.777754\n",
      "C0002      C0133  0.966879      C0134  0.931345      C0159  0.903061\n",
      "C0003      C0166  0.882103      C0128  0.854873      C0144  0.797472\n",
      "C0004      C0017  0.915365      C0113  0.910606      C0194  0.893890\n",
      "C0005      C0197  0.948760      C0140  0.885635      C0007  0.882779\n"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary to store the top 3 lookalikes for each customer\n",
    "lookalike_dict = {}\n",
    "\n",
    "# Iterate over each customer to find the top 3 similar customers\n",
    "for customer_id in customer_features['CustomerID'][:20]:  # First 20 customers (C0001 to C0020)\n",
    "    # Get the similarity scores for the current customer\n",
    "    similarity_scores = cosine_sim_df[customer_id]\n",
    "    \n",
    "    # Exclude the customer itself from the recommendations\n",
    "    similarity_scores = similarity_scores.drop(customer_id)\n",
    "    \n",
    "    # Get the top 3 most similar customers (highest similarity scores)\n",
    "    top_3_customers = similarity_scores.nlargest(3)\n",
    "    \n",
    "    # Store the results in the dictionary\n",
    "    lookalike_dict[customer_id] = {\n",
    "        'Lookalike1': top_3_customers.index[0], \n",
    "        'Score1': top_3_customers.values[0],\n",
    "        'Lookalike2': top_3_customers.index[1],\n",
    "        'Score2': top_3_customers.values[1],\n",
    "        'Lookalike3': top_3_customers.index[2],\n",
    "        'Score3': top_3_customers.values[2]\n",
    "    }\n",
    "\n",
    "# Convert the dictionary to a DataFrame for easy viewing\n",
    "lookalike_df = pd.DataFrame.from_dict(lookalike_dict, orient='index')\n",
    "\n",
    "# Save the result to a CSV file\n",
    "lookalike_df.to_csv('Lookalike.csv')\n",
    "\n",
    "# Display the first few rows of the resulting DataFrame\n",
    "print(lookalike_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f9173ca8-4d3e-4bf3-8fbd-002a7924e137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Lookalike1    Score1 Lookalike2    Score2 Lookalike3    Score3\n",
      "C0001      C0069  0.944409      C0146  0.784552      C0127  0.777754\n",
      "C0002      C0133  0.966879      C0134  0.931345      C0159  0.903061\n",
      "C0003      C0166  0.882103      C0128  0.854873      C0144  0.797472\n",
      "C0004      C0017  0.915365      C0113  0.910606      C0194  0.893890\n",
      "C0005      C0197  0.948760      C0140  0.885635      C0007  0.882779\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming cosine_sim_df is your cosine similarity DataFrame\n",
    "# and customer_features is your customer feature DataFrame.\n",
    "\n",
    "# Initialize a dictionary to store the top 3 lookalikes for each customer\n",
    "lookalike_dict = {}\n",
    "\n",
    "# Iterate over each customer to find the top 3 similar customers\n",
    "for customer_id in customer_features['CustomerID'][:20]:  # First 20 customers (C0001 to C0020)\n",
    "    # Get the similarity scores for the current customer\n",
    "    similarity_scores = cosine_sim_df[customer_id]\n",
    "    \n",
    "    # Exclude the customer itself from the recommendations\n",
    "    similarity_scores = similarity_scores.drop(customer_id)\n",
    "    \n",
    "    # Get the top 3 most similar customers (highest similarity scores)\n",
    "    top_3_customers = similarity_scores.nlargest(3)\n",
    "    \n",
    "    # Store the results in the dictionary with both customer IDs and their similarity scores\n",
    "    lookalike_dict[customer_id] = {\n",
    "        'Lookalike1': top_3_customers.index[0], \n",
    "        'Score1': top_3_customers.values[0],\n",
    "        'Lookalike2': top_3_customers.index[1],\n",
    "        'Score2': top_3_customers.values[1],\n",
    "        'Lookalike3': top_3_customers.index[2],\n",
    "        'Score3': top_3_customers.values[2]\n",
    "    }\n",
    "\n",
    "# Convert the dictionary to a DataFrame for easy viewing\n",
    "lookalike_df = pd.DataFrame.from_dict(lookalike_dict, orient='index')\n",
    "\n",
    "# Save the result to a CSV file\n",
    "lookalike_df.to_csv('Lookalike.csv')\n",
    "\n",
    "# Display the first few rows of the resulting DataFrame\n",
    "print(lookalike_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48ed491-8126-46af-854c-8f2bd8c7a6af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
